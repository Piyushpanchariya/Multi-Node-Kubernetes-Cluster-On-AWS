Launch three instances on aws cloud and then do so,



Run These Commands In All The Nodes:

>sudo su - root
>yum install docker -y
>systemctl enable docker --now

>cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

>yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

>systemctl enable kubelet --now

>cat /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"]
}

>systemctl restart docker

>yum install iproute-tc

>cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

>sudo sysctl --system

--------------*******************************----------------


Run These Commands In The Master-Node:

>kubeadm init --pod-network-cidr=<Ip_rang_of_pod_you_want>
///you get a command/token when you run this command for worker node to connect with this master-node, so run that token command in the worker ndoe to connect to this ///master node 
>mkdir -p $HOME/.kube
>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
>sudo chown $(id -u):$(id -g) $HOME/.kube/config

>kubectl get nodes
///nodes are showing but they aren't in ready state coz they need to have connectivity inside the nodes, for that we need to install flannel virtual network for them

>kubectl apply -f https://github.com/coreos/flannel/raw/master/Documentation/kube-flannel.yml

///now all nodes are ready and you can deploy your resources on the kuberntes multi node cluster

